{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Speech To Text\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import librosa\n",
    "import openai\n",
    "import soundfile as sf\n",
    "\n",
    "import yt_dlp as youtube_dl\n",
    "from youtube_dl.utils import DownloadError\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "print(openai.__version__)\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None, \"GO TO .env FILE AND SET OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increment File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_incr(path, extension=\".mp3\"):\n",
    "    audio_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.endswith(extension):\n",
    "                audio_files.append(os.path.join(root, f))\n",
    "\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Youtube to Mp3 Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_to_mp3(youtube_url: str, output_dir: str) -> str:\n",
    "    ydl_config = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }\n",
    "        ],\n",
    "        \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
    "        \"verbose\": True,\n",
    "    }\n",
    "\n",
    "    if not os.path.exists(output_dir): # null check for dir \n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    print(f\"Capturing mp3 from: {youtube_url}\")\n",
    "\n",
    "    try:\n",
    "        with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "            ydl.download([youtube_url])\n",
    "    except DownloadError:\n",
    "        with youtube_dl.YoutubeDL(ydl_config) as ydl:\n",
    "            ydl.download([youtube_url])\n",
    "\n",
    "    audio_filename = file_incr(output_dir)[0]\n",
    "    return audio_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Break down files \n",
    "gpt api caps at 25mb per call, so larger files will need to be quantized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_mp3(filename, segment_length: int, output_dir):\n",
    "\n",
    "    print(f\"Chunking audio to {segment_length} second segments...\")\n",
    "\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    audio, sr = librosa.load(filename, sr=44100)\n",
    "\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "    num_segments = int(duration / segment_length) + 1\n",
    "\n",
    "    print(f\"Quantizing {num_segments} chunks...\")\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_length * sr\n",
    "        end = (i + 1) * segment_length * sr\n",
    "        segment = audio[start:end]\n",
    "        sf.write(os.path.join(output_dir, f\"segment_{i}.mp3\"), segment, sr)\n",
    "\n",
    "    chunked_audio_files = file_incr(output_dir)\n",
    "    return sorted(chunked_audio_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe Audio with gpt whisper api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_files: list, output_file=None, model=\"whisper-1\") -> list:\n",
    "\n",
    "    print(\"Converting audio to text...\")\n",
    "\n",
    "    transcripts = []\n",
    "    for audio_file in audio_files:\n",
    "        with open(audio_file, \"rb\") as audio:\n",
    "            response = openai.audio.transcriptions.create(\n",
    "                model=model,\n",
    "                file=audio,\n",
    "                response_format=\"json\",\n",
    "                # response_format=\"verbose_json\", timestamp_granularities=[\"word\"], #TODO take a look at \"verbose_json\" -> may have some interesting applications\n",
    "                \n",
    "            )\n",
    "            print(response)\n",
    "            transcripts.append(response.text)  # or response['text'], depending on the structure\n",
    "\n",
    "    if output_file is not None:\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for transcript in transcripts:\n",
    "                file.write(transcript + \"\\n\")\n",
    "    json.dumps(transcripts)\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_transcriptions(youtube_url, outputs_dir):\n",
    "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
    "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
    "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
    "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
    "    segment_length = 10 * 60  # chunk to 10 minute segments\n",
    "\n",
    "    if os.path.exists(outputs_dir):\n",
    "        # delete the outputs_dir folder and start from scratch\n",
    "        shutil.rmtree(outputs_dir)\n",
    "        os.mkdir(outputs_dir)\n",
    "\n",
    "    audio_filename = youtube_to_mp3(youtube_url, output_dir=raw_audio_dir)\n",
    "\n",
    "    chunked_audio_files = quantize_mp3(\n",
    "        audio_filename, segment_length=segment_length, output_dir=chunks_dir\n",
    "    )\n",
    "\n",
    "    transcriptions = transcribe_audio(chunked_audio_files, transcripts_file)\n",
    "    \n",
    "    # print(transcriptions)\n",
    "    \n",
    "    return transcriptions\n",
    "    \n",
    "    \n",
    "youtube_url = \"https://www.youtube.com/watch?v=fGdmjSYJtb8\"\n",
    "outputs_dir = \"outputs/\"    \n",
    "transcription = print_transcriptions(youtube_url, outputs_dir)\n",
    "pre_processed_transcript = json.dumps(transcription)\n",
    "\n",
    "\n",
    "print(pre_processed_transcript)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing with gpt \n",
    "Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant. Your task is to correct any spelling discrepancies in the transcribed text. Only add necessary punctuation such as periods, commas, and capitalization, and use only the context provided.\"\n",
    "\n",
    "#TODO: work on how to work around token limit \n",
    "def gen_enhanced_transcript(temperature, system_prompt, pre_processed_transcipt):\n",
    "    enhanced_transcript = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": pre_processed_transcipt\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return enhanced_transcript\n",
    "\n",
    "final_transcript = gen_enhanced_transcript(0, system_prompt, pre_processed_transcript) \n",
    "print(final_transcript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-transcription",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
